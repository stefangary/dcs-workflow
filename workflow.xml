<tool id='NA' name='NA'>
  <command interpreter='bash'>main.sh</command>
  <cancel interpreter='bash'>cancel.sh</cancel>
  <inputs>
    <param 
        name='metering_user' 
        label='metering_user' 
        type='hidden' 
        value='__metering_user__'  
    ></param>
    <param 
        name='metering_ip' 
        label='metering_ip' 
        type='hidden' 
        value='34.132.102.42'  
    ></param>
<section name='dcs' type='section' title='3DCS Options' expanded='true'>
        <param 
            name="dry_run" 
            type="boolean" 
            truevalue="Yes" 
            falsevalue="No" 
            checked="False" 
            value="false"
            label="Dry run?" 
            help='Dry run generates the macroScript.txt file and executes every step of the workflow except running 3DCS'  
        ></param>
        <param 
            name='version' 
            type='select' 
            label='3DCS Version' 
            help='Select the 3DCS version' 
            multiple='false'
        >
            <option value="8.0.0.2"  selected="true">8.0.0.2</option>
            <option value="7.10.0.2" >7.10.0.2</option>
        </param>
        <param 
            name='analysis_type' 
            type='select' 
            label='Analysis Type' 
            help='Select Montecarlo simulation or contributor analysis (sensitivity)' 
            multiple='false'
        >
            <option value="montecarlo"  selected="true">Monte Carlo Simulation</option>
            <option value="sensitivity" >Contributor Analysis</option>
        </param>
        <param name='bucket_id' 
            label='Bucket ID or namespace' 
            type='text' 
            help='Type in the bucket ID string or namespace in the format [bucket-owner]/[bucket-name]' 
        ></param>
        <param 
            name='model_directory' 
            label='Model Path' 
            type='text' 
            help='Directory within the bucket with the model and all the required files' 
        ></param>
        <param 
            name='output_directory' 
            label='Output Path' 
            type='text' 
            help='Output directory within the bucket to store outputs and logs. It cannot be inside the Model Directory!' 
        ></param>
        <param 
            name='num_seeds' 
            type='integer' 
            label='Number of Monte Carlo Simulations' 
            min='1' 
            max='100000' 
            value='2000'
            depends_on='dcs.analysis_type'
            show_if="montecarlo"
        ></param>
        <param 
            name='concurrency' 
            type='integer' 
            label='Number of Workers' 
            min='1' 
            max='100' 
            value='2' 
            help='Number of workers used to run the simulations. A SLURM job is submitted for each worker.' 
        ></param>
        <param 
            name='thread' 
            type='integer' 
            label='Number of Threads per Worker' 
            min='1' 
            max='64' 
            value='1' 
            help='Number of threads used to run the simulation. Be aware that N threads require more than N times the memory needed for a single thread.'
        ></param>
    </section>
    <section name='pwrl_001_simulation_executor' type='section' title='Simulation Executor' expanded='true'>
        <param 
            name='monitoring_conda_dir' 
            label='PW Conda Directory' 
            type='hidden' 
            value='/dcs/pw/miniconda'
        ></param>
        <param 
            name='monitoring_conda_env' 
            label='PW Conda Directory' 
            type='hidden' 
            value='psutil'
        ></param>
        <param 
            name='resource' 
            type='computeResource' 
            label='Resource' 
            hideUserWorkspace='true' 
            help='Resource to run the simulation task'>
        </param>
        <param 
            name='jobschedulertype' 
            label='Select Controller, SLURM Partition or PBS Queue' 
            type='hidden' 
            value='SLURM' 
        >
        </param>
       <param
           name='_sch__dd_partition_e_'
           label='SLURM partition'
           type='dynamicPartitionDropdown'
           resource='pwrl_001_simulation_executor.resource'
           help='Partition to submit the interactive job. Leave empty to let SLURM pick the optimal option.'
           optional='true'  
           dependent='false'
       ></param>
       <param 
            name='max_workers_per_node' 
            label='Max Workers per Node' 
            type='integer' 
            min="1" 
            max="10" 
            help='To reduce compute costs, estimate the required memory and maximize memory utilization by fitting as many workers as possible in a single node.'
            value='1'
        ></param>
        <param 
            name='_sch__dd_time_e_' 
            label='Walltime' 
            type='text' 
            help='Maximum walltime per job' 
            value='02:00:00'
            optional='true' 
        ></param>
        <param 
            name='scheduler_directives' 
            label='Scheduler directives' 
            type='text' 
            help='e.g. --mem=1000;--gpus-per-node=1 - Use the semicolon character ; to separate parameters. Do not include the SBATCH keyword.' 
            value=''
            optional='true'  
        ></param>
    </section>
    <section name='pwrl_002_merge_executor' type='section' title='Merge Executor' expanded='true'>
        <param 
            name='monitoring_conda_dir' 
            label='PW Conda Directory' 
            type='hidden' 
            value='/dcs/pw/miniconda'
        ></param>
        <param 
            name='monitoring_conda_env' 
            label='PW Conda Directory' 
            type='hidden' 
            value='psutil'
        ></param>
        <param 
            name='resource' 
            type='computeResource' 
            label='Resource' 
            hideUserWorkspace='true' 
            help='Resource to run the simulation task'>
        </param>
        <param 
            name='jobschedulertype' 
            label='Select Controller, SLURM Partition or PBS Queue' 
            type='hidden' 
            value='SLURM' 
        >
        </param>
        <param
           name='_sch__dd_partition_e_'
           label='SLURM partition'
           type='dynamicPartitionDropdown'
           resource='pwrl_002_merge_executor.resource'
           help='Partition to submit the interactive job. Leave empty to let SLURM pick the optimal option.'
           optional='true'  
           dependent='false'
        ></param>
        <param 
            name='max_workers_per_node' 
            label='Max Workers per Node' 
            type='integer' 
            min="1" 
            max="10" 
            help='To reduce compute costs, estimate the required memory and maximize memory utilization by fitting as many workers as possible in a single node.'
            value='1'
        ></param>
        <param 
            name='_sch__dd_time_e_' 
            label='Walltime' 
            type='text' 
            help='Maximum walltime per job' 
            value='02:00:00'
            optional='true' 
        ></param>
        <param 
            name='scheduler_directives' 
            label='Scheduler directives' 
            type='text' 
            help='e.g. --mem=1000;--gpus-per-node=1 - Use the semicolon character ; to separate parameters. Do not include the SBATCH keyword.' 
            value=''
            optional='true'  
        ></param>
    </section>
    </inputs>
</tool>
